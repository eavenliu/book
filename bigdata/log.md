# 日志

基本上所有的应用程序都离不开一个最基础的概念：日志。有时称为预写日志或提交日志或事务日志，日志也是许多分布式数据系统和实时应用程序体系结构的核心。

在不了解日志的情况下，您无法完全理解数据库，NoSQL存储，键值存储，复制，paxos，hadoop，版本控制或几乎任何软件系统; 然而，大多数软件工程师并不熟悉它们。我想改变这一点。在这篇文章中，我将向您介绍有关日志的所有信息，包括日志以及如何使用日志进行数据集成，实时处理和系统构建。

# 核心抽象

## 什么是日志？
**日志可能是最简单的存储抽象。** 它是仅追加的，按时间排序的完全有序的记录序列。如下：

![image](https://note.youdao.com/yws/res/21248/91E9300000AA4B4F824D38EED16173BE)

记录附加到日志的末尾，读取从左到右进行。每个条目都分配有唯一的顺序日志条目号。

记录的顺序定义了“时间”的概念，因为左边的条目被定义为比右边的条目更旧。**日志条目号可以被认为是条目的“时间戳”**。将这种排序描述为时间概念起初看起来有点奇怪，但它具有与任何特定物理时钟分离的便利特性。当我们进入分布式系统时，此属性将变得至关重要。

**日志的核心目的在于：它们记录发生的事件及其时间，并按照时间顺序追加的。**

但在我们走得太远之前，让我澄清一些有点令人困惑的事情。每个程序员都熟悉另一个日志记录定义 - **应用程序可能使用syslog或log4j写入本地文件的非结构化错误消息或跟踪信息**。为清楚起见，我将其称为“**应用程序日志记录**”。应用程序日志是我描述的日志概念的退化形式。最大的区别是文本日志主要是供人阅读，**而我所描述的“日志”或“数据日志”是为编程访问而构建的**。

## 日志在传统数据库的角色
**日志在数据库中的主要体现在于当数据库出现崩溃后恢复的关键**。为了保证数据库操作的原子性和持久性，数据库使用日志来写出有关他们将要修改的记录的信息，然后将更改应用于它维护的所有各种数据结构。日志是发生的事件的记录，每个表或索引是将该历史记录投影到一些有用的数据结构或索引中。由于日志会立即保留，因此在崩溃时将其用作恢复所有其他持久性结构的权威来源。

随着时间的推移，日志的使用从ACID的实现细节发展到在**数据库之间复制数据**的方法。事实证明，数据库上发生的更改顺序正是保持远程副本数据库同步所需的。Oracle，MySQL和PostgreSQL包括日志传送协议，用于将部分日志传输到充当从属服务器的副本数据库。Oracle已将日志产品化为非oracle数据订阅者的通用数据订阅机制，其XStream和GoldenGate以及MySQL和PostgreSQL中的类似工具是许多数据架构的关键组件。

由于这个起源，机器可读日志的概念主要局限于数据库内部。**使用日志作为数据订阅的机制似乎几乎是偶然出现的。但这种抽象是支持各种消息传递，数据流和实时数据处理的理想选择。**

## 日志在分布式系统的角色
日志解决的两个问题：排序更改和分发数据 - 在分布式数据系统中更为重要。同意排序更新（或同意不同意和应对副作用）是这些系统的核心设计问题。

### 状态机复制原则
分布式系统的以日志为中心的方法源于一个简单的观察，我称之为**状态机复制原则**（State Machine Replication Principle）：**如果两个相同的确定性过程以相同的状态开始并以相同的顺序获得相同的输入，则它们将产生相同的输出并以相同的状态结束**。

**确定性（Deterministic）** 意味着处理不依赖于时间，并且不允许任何其他“带外数据（out-of-band，OOB）”输入影响其结果。例如，其输出受线程的特定执行顺序或通过调用gettimeofday或某些其他不可重复的事物影响的程序通常被认为是非确定性的。

> 传输层协议使用带外数据（out-of-band，OOB）来发送一些重要的数据，如果通信一方有重要的数据需要通知对方时，协议能够将这些数据快速地发送到对方。为了发送这些数据，协议一般不使用与普通数据相同的通道，而是使用另外的通道。linux系统的套接字机制支持低层协议发送和接受带外数据。但是TCP协议没有真正意义上的带外数据。为了发送重要协议，TCP提供了一种称为紧急模式（urgent mode）的机制。TCP协议在数据段中设置URG位，表示进入紧急模式。接收方可以对紧急模式采取特殊的处理。很容易看出来，这种方式数据不容易被阻塞，并且可以通过在我们的服务器端程序里面捕捉SIGURG信号来及时接受数据。

**状态（state）** 是进程处理结束时机器上的数据，包括内存和磁盘。

**相同的顺序获得相同的输入** -- 这是日志触发的地方。这是一个非常直观的概念：如果您将两个确定的代码片段输入相同的输入日志，它们将产生相同的输出。

当你理解状态机复制原则时，这个原则没有任何复杂或深刻的东西：**它或多或少等于说“确定性处理是确定性的”。尽管如此，我认为它是分布式系统设计的一般工具之一。**

**状态机复制原则带来了一个好处**：作为索引当前日志条目的时间戳，可以充当副本的状态时钟（即当前复制偏移位置）。我们可以用单个数字描述每个副本，它是已处理的最大日志条目的时间戳。此时间戳与日志相结合，可以唯一地捕获副本的整个复制状态。

不同的人群不同地描述了日志的使用。数据库人员通常区分物理和逻辑日志记录。物理日志记录意味着记录更改的每一行的内容。逻辑日志记录意味着不记录已更改的行，而是记录导致行更改的SQL命令（insert，update和delete语句）。

### 状态机模型
分布式系统设计通常区分处理（processing）和复制（replication）。

“状态机模型”通常是指**“主动-主动 模型”** ：我们保留传入请求的日志，并且每个副本处理每个请求。修改一下思路=变为**“主-备 模型”** ：选择其中一个副本作为领导者，并允许该领导者按照请求到达的顺序处理请求，并从处理请求中注销对其状态的更改。其他副本复制领导者的状态改变，以便他们同步并准备好在领导者失败时接管领导者。

![image](https://note.youdao.com/yws/res/21362/7BFF1D1698414CE194DAD9E9176A0865)

要了解这两种方法之间的区别，让我们看一下玩具问题。考虑一个复制的“算术服务”，它保持一个数字作为其状态（初始化为零）并对该值应用加法和乘法。
- “主动 - 主动 模型”方法可能会注销要应用的转换，比如“+1”，“* 2”等。每个副本都会应用这些转换，因此会经历相同的值集。
- “主 - 备 模型”方法将领导者主机执行转换并注销结果，比如说“1”，“3”，“6”等。

这个例子也清楚地说明了**为什么顺序是确保一致性的关键。复制品：重新排序加法和乘法将产生不同的结果**。

**分布式日志可以看作是模拟共识问题的数据结构**。毕竟，日志代表了一系列关于“下一个”追加值的决定。你必须详细分析一下Paxos算法系列中的日志，尽管日志构建是他们最常见的实际应用。对于Paxos，这通常使用称为“**multi-paxos**”的协议的扩展来完成，**该协议将日志建模为一系列共识问题，一个用于日志中的每个插槽**。该日志在其他协议（如ZAB ，RAFT和Viewstamped Replication）中更为突出，后者直接模拟了维护分布式一致日志的问题。

## 变更日志和表
让我们回到数据库一点点。变更日志和表之间存在一种紧密的二元性。该日志类似于所有贷记和借方以及银行流程的清单; 表格是所有当前帐户余额。如果您有更改日志，则可以应用这些更改以创建捕获当前状态的表。此表将记录每个密钥的最新状态（截至特定日志时间）。有一种感觉，**日志是更基本的数据结构：除了创建原始表，您还可以转换它以创建各种派生表**。（是的，表可以表示非关系人员的键控数据存储。）

此过程也是相反的：如果您有一个表更新，您可以记录这些更改并发布所有更新的“更改日志”到表的状态。此更改日志正是您支持近实时副本所需的内容。因此，在这个意义上，您可以将表和事件视为双重：
**表支持静态数据并记录捕获更改**。**日志的神奇之处在于，如果它是一个完整的更改日志，它不仅包含表的最终版本的内容，还允许重新创建可能已存在的所有其他版本。实际上，它是表的每个先前状态的一种备份。**

比如**源代码版本控制** ，源码控制和数据库之间存在密切关系。**版本控制解决了与分布式数据系统必须解决的问题非常相似的问题-管理分布式，并发的状态变化**。
- 版本控制系统通常对补丁序列进行建模，这实际上是一个日志。您可以直接与当前代码的签出“快照”进行交互，该快照与表格类似。
- 您将注意到，在版本控制系统中，与其他分布式有状态系统一样，复制通过日志进行：**更新时，只需下载修补程序并将其应用于当前快照**。


# 构建服务
基于日志的核心抽象，怎么通过日志来构建合理的服务？
- 数据集成：在所有存储和处理系统中轻松提供组织的所有数据
- 实时数据处理：计算派生数据流
- 分布式系统设计：实际系统如何通过以日志为中心的设计进行简化

这些使用都解决了日志作为独立服务的想法。

在每种情况下，**日志的有用性来自日志提供的简单功能：生成持久的，可重复播放的历史记录**。令人惊讶的是，这些问题的核心是能够以确定的方式让许多机器以自己的速率回放历史记录。

## 数据集成
**数据集成使同一组织内的所有服务和系统中都可以使用所有数据。** 类似概念可以参考[ETL](https://en.wikipedia.org/wiki/Extract,_transform,_load)（描述了对于数据的提取、转换、加载，常用与数据仓库）

有效使用数据遵循一种[马斯洛的需求层次](https://en.wikipedia.org/wiki/Maslow's_hierarchy_of_needs)。金字塔的基础包括捕获所有相关数据，能够将它们组合在一个适用的处理环境中（无论是花哨的实时查询系统还是文本文件和python脚本）。这些数据需要以统一的方式建模，以便于阅读和处理。一旦处理了以统一方式捕获数据的这些基本需求，就可以合理地使用基础设施来以各种方式处理这些数据 - MapReduce，实时查询系统等。

值得注意的是：如果没有可靠和完整的数据流，Hadoop集群只是一个非常昂贵且难以组装的框架。一旦数据和处理可用，人们就可以关注更好的数据模型问题和一致易懂的语义。最后，集中可以转向更复杂的处理 - 更好的可视化，报告，算法处理和预测。

所以，**构建可靠的数据流是一切数据上层建瓴的基石**。**那么如何构建可靠的数据流？**

**数据的两种趋势**：
- 事件数据的增加：事件数据记录发生的事情而不是事物。在Web系统中，这意味着用户活动记录，还包括可靠地操作和监视数据中心价值的机器所需的机器级事件和统计信息。人们倾向于将这种“日志数据”称为“应用日志数据”，因为它经常写入应用程序日志，但这会使形式与功能混淆。
- 专业数据系统的爆发增长：这些系统在过去五年中变得流行而且被开源。专业系统存在：OLAP（Druid），搜索（Elasticsearch），简单的在线存储（slideshare），批量处理（hadoop），图形分析（graphlab），实时计算（flink、spark）。更多品种的更多数据的组合以及将这些数据引入更多系统的愿望导致巨大的数据集成问题。

**日志结构化数据流**
**日志是处理系统之间数据流的自然数据结构**。 方法很简单：获取组织的所有数据并将其放入中央日志中以进行实时订阅。

每个逻辑数据源都可以建模为自己的日志。数据源可以是记录事件（例如点击或页面视图）的应用程序，也可以是接受修改的数据库表。每个订阅系统尽可能快地从此日志中读取，将每个新记录应用到其自己的存储，并在日志中偏移读取条目指针。订户可以是任何类型的数据系统 - 缓存，Hadoop，另一个站点中的另一个数据库，搜索系统等。

![image](https://note.youdao.com/yws/res/21399/D322B2586BEA4EBF874BC9013E966C81)

日志为每个更改提供了逻辑时钟的概念，这使得关于彼此的不同订阅者的状态的推理变得更加简单，因为每个订阅者具有他们自己已经读取的“时间点”。

**日志还充当缓冲区，使数据生成与数据消耗异步**。这很重要，原因很多，但特别是当有多个订阅者可能以不同的速率消费时。这意味着订阅系统可能会崩溃或停机以进行维护，并在返回时赶上：订阅者按其控制的速度消耗。诸如Hadoop或数据仓库之类的批处理系统可能仅每小时或每天消耗，而实时查询系统可能需要高达一秒。原始数据源和日志都不知道各种数据目标系统，因此可以添加和删除消费者系统而不改变管道。

特别重要的是：**目标系统只知道日志而不知道原始系统的任何细节**。

### 日志的优雅使用
通过上面的分析，我们可以知道通过日志可以构建结构化的数据流来在两个不同的系统中流通。

但为每个数据源和目标构建自定义数据加载，显然是不可行的，假设我们有数十个数据系统和数据存储库。连接所有这些将导致在每对系统之间构建自定义管道，如下所示：

![image](https://note.youdao.com/yws/res/21427/5CE04494CC9443A08A201AEEA998D19F)

请注意，数据通常在两个方向上流动，因为许多系统（数据库，Hadoop）都是数据传输的源和目标。这意味着我们最终会为每个系统构建两个管道：一个用于获取数据输入，另一个用于传输数据输出。

上面的架构显然会很难操作，所以我们需要一个通用的模式：

![image](https://note.youdao.com/yws/res/21436/52115D13211449739BE33DE1237FF744)

我们需要尽可能地将每个消费者与数据来源隔离开来。理想情况下，它们应该只与一个数据存储库集成，以便访问所有内容。这也是日志即服务--Kafka存在的意义。

### 与ETL（Extract-Transform-Load）和数据仓库的关系
**数据仓库**旨在成为支持分析的清洁，集成数据的存储库。数据仓库方法涉及定期从源数据库中提取数据，将其变为某种可理解的形式，并将其加载到中央数据仓库中。拥有包含所有数据的干净副本的中心位置对于数据密集型分析和处理来说是非常宝贵的资产。从高层次来看，无论您使用的是传统数据仓库（如Oracle，Teradata还是Hadoop），这种方法都不会发生太大变化，但您可能会改变加载和调整的顺序。

**以数据为中心的组织的关键问题是将干净的集成数据耦合到数据仓库**。**数据仓库是一种批量查询基础结构，非常适合于多种报告和临时分析，特别是当查询涉及简单的计数，聚合和过滤时**。但是，将批处理系统作为清洁完整数据的唯一存储库意味着数据不适用于需要实时馈送实时处理，搜索索引，监视系统等的系统。

在我看来，ETL实际上是两件事。首先，它是一个提取和数据清理过程 - 基本上解放了锁定在组织中各种系统中的数据，并删除了系统特定的无意义。其次，为数据仓库查询重新构建数据（即，使其适合关系数据库的类型系统，强制转换为星形或雪花模式，可能分解为高性能列 格式等）。将这两件事混为一谈是个问题。清晰，集成的数据存储库应该是实时可用的，以及低延迟处理以及其他实时存储系统中的索引。

更好的方法是使用**中央管道（日志）**，使用定义良好的API来添加数据。与此管道集成并提供清晰，结构良好的数据源的责任在于此数据源的生产者。这意味着，作为系统设计和实施的一部分，他们必须考虑将数据输出并进入结构良好的形式以便交付到中央管道的问题。添加新的存储系统对数据仓库团队来说并不重要，因为它们具有集中的中心点。数据仓库团队只处理从中央日志加载结构化数据源并执行特定于其系统的转换的更简单问题。

![image](https://note.youdao.com/yws/res/21455/579EF48C4C574726AC4EF864B7F3030A)

当考虑采用传统数据仓库之外的其他数据系统时，关于组织可扩展性的这一点变得尤为重要。例如，假设有人希望在组织的完整数据集上提供搜索功能。或者，假设有人希望通过实时趋势图和警报提供数据流的亚秒级监控。在任何一种情况下，传统数据仓库甚至Hadoop集群的基础架构都是不合适的。更糟糕的是，为支持数据库负载而构建的ETL处理管道可能无法用于为这些其他系统提供服务，这使得这些基础架构的引导成为采用数据仓库的一项重大任务。这可能不是'' 可行并且可能有助于解释为什么大多数组织没有这些功能可以轻松地用于他们的所有数据。相比之下，如果组织已经构建了统一，结构良好的数据源，则任何新系统都可以完全访问所有数据，只需要一点点的集成管道即可连接到管道。

此体系结构还为特定清理或转换所在的位置提供了一组不同的选项：
1. 在将数据添加到公司范围的日志之前，可以由数据生产者完成。
2. 它可以作为日志的实时转换完成（这反过来会生成一个新的转换日志）
3. 它可以作为加载过程的一部分进入某个目标数据系统

最好的模型是在数据发布者将数据发布到日志之前完成清理。这意味着确保数据处于规范形式，并且不会保留产生数据的特定代码或可能维护它的存储系统的任何保留。这些细节最好由创建数据的团队处理，因为他们最了解自己的数据。在这个阶段应用的任何逻辑都应该是无损且可逆的。

任何可以实时完成的增值转换都应该在生成的原始日志源上进行后处理。这将包括事件数据的会话化或添加其他一般感兴趣的派生字段之类的事情。原始日志仍然可用，但此实时处理会生成包含扩充数据的派生日志。

最后，只应作为加载过程的一部分执行特定于目标系统的聚合。这可能包括将数据转换为特定的星形或雪花模式，以便在数据仓库中进行分析和报告。因为这个阶段（最自然地映射到传统的ETL过程）现在在更清晰，更均匀的流集上完成，所以应该大大简化。

## 构建可扩展日志--Kafka的处理
**如果你希望保留一个提交日志，该日志充当消费者在网站上发生的所有事情的多用户实时日志，则可扩展性将是主要挑战**。使用日志作为通用集成机制永远会只是一个优雅的幻想，如果我们不能构建一个快速，廉价和可扩展的日志，足以支撑大规模业务使用。

系统人员通常将分布式日志视为缓慢，重量级的抽象（并且通常仅将其与Zookeeper可能适合的“元数据”使用类型相关联）。但是，通过专注于记录大数据流的深思熟虑的实现，这不一定是真的。

在Kafka上使用了一些设计技巧来支持这种规模：
1. 对日志进行分区；
2. 通过批量读取和写入来优化吞吐量；
3. 避免不必要的数据副本。

为了允许水平缩放，我们将日志切换为分区：

![image](https://note.youdao.com/yws/res/21995/506260EF8E2C4989ADCCD3D6637D0881)

**每个分区都是一个完全有序的日志，但是分区之间没有全局排序（除了可能包含在消息中的一些挂钟时间）。** 将消息分配给特定分区是可由编写者控制的，大多数用户选择通过某种密钥（例如用户id）进行分区。分区允许在没有分片之间协调的情况下进行日志附加，并允许系统的吞吐量与Kafka群集大小线性地扩展。

**每个分区都在可配置数量的副本中进行复制，每个副本都具有分区日志的相同副本**。在任何时候，他们中的任何一个将充当领导者; 如果领导者失败，其中一个副本将接任领导。

**跨分区缺乏全局顺序是一个限制，但我们还没有发现它是一个主要的顺序。实际上，与日志的交互通常来自数百或数千个不同的进程，因此谈论对其行为的总体顺序没有意义**。相反，我们提供的保证是每个分区都是订单保留，并且Kafka保证从单个发件人追加到特定分区将按照它们发送的顺序传递。

像文件系统一样，日志很容易针对线性读写模式进行优化。日志可以将小型读取和写入组合在一起，形成更大的高吞吐量操作。Kafka积极地追求这种优化。在发送数据，写入磁盘，服务器之间的复制，数据传输到使用者以及确认提交的数据时，从客户端到服务器进行批处理。

最后，Kafka使用在内存日志，磁盘上日志和网络数据传输之间维护的简单二进制格式。这使我们可以利用许多优化，包括零拷贝数据传输。

这些优化的累积效果是，您通常可以以磁盘或网络支持的速率写入和读取数据，即使在维护远远超过内存的数据集时也是如此。

## 日志和实时流处理
到目前为止，我只描述了从一个地方到另一个地方复制数据的奇特方法。但是，在存储系统之间切换字节并不是故事的结束。事实证明，“log”是“流”的另一个词，而**日志是流处理的核心**。

### 流处理究竟是什么？
我认为流处理更广泛：**用于连续数据处理的基础设施**。我认为计算模型可以像MapReduce或其他分布式处理框架一样通用，但能够产生低延迟的结果。

处理模型的真正驱动力是数据收集方法。批量收集的数据自然是批量处理的。当连续收集数据时，它会自然地连续处理。

![image](https://note.youdao.com/yws/res/22015/CC5B2F6CEE1D4966A313588B696B67C6)

流处理中最有趣的方面与流处理系统的内部无关，而是与如何扩展我们对早期数据集成讨论中数据馈送的概念有关。我们主要讨论了主数据的提要或日志 - 在执行各种应用程序时产生的事件和数据行。但是流处理允许我们还包括从其他提要计算出的提要。这些派生的供稿与消费者看起来没有什么不同，然后是计算它们的主要数据的供稿。这些派生的源可以封装任意复杂性。

流处理作业将是从日志中读取并将输出写入日志或其他系统的任何内容。他们用于输入和输出的日志将这些过程连接到处理阶段的图表中。实际上，以这种方式使用集中式日志，您可以将所有组织的数据捕获，转换和流视为一系列写入它们的日志和进程。

流处理器根本不需要花哨的框架：**它可以是从日志读取和写入的任何进程或进程集，但可以提供额外的基础结构和支持来帮助管理处理代码。**

### 有状态的实时处理
**一些实时流处理只是无状态一次转换，但许多用途是更精细的计数，聚合或流中的窗口连接。**

例如，人们可能希望丰富事件流（比如点击流），其中包含有关用户执行点击效果的信息，将点击流加入用户帐户数据库。总是，这种处理最终需要处理器维护某种状态：例如，在计算计数时，您有到目前为止要维护的计数。如果处理器本身可能出现故障，如何才能正确维护这种状态呢？

最简单的替代方案是将状态保持在内存中。但是，如果该处理进程崩溃，它将失去其中间状态。如果仅在窗口上维护状态，则该过程可能会回退到窗口开始的日志中的点。但是，如果一个人计算超过一小时，这可能是不可行的。

另一种方法是简单地将所有状态存储在远程存储系统中，并通过网络连接到该存储。这样做的问题是没有数据的位置和大量的网络往返。

**我们怎样才能支持像我们处理分区的“表格”这样的东西？**

流处理器可以将其状态保存在本地“表”或“索引”中 - 例如bdb，leveldb，甚至是更不寻常的东西，例如Lucene或fastbit索引。该商店的内容来自其输入流（首先可能应用任意转换）。它可以记录它保留的本地索引的更改日志，以允许它在崩溃和重新启动时恢复其状态。此机制允许一种通用机制，用于将传统流数据本地的任意索引类型中的共分区状态保持不变。

当进程失败时，它会从更改日志中恢复其索引。日志是将本地状态转换为一次备份时的一种增量记录。

这种状态管理方法具有优雅的特性，即处理器的状态也作为日志维护。我们可以像记录数据库表的更改一样考虑这个日志。实际上，处理器有一些非常类似于与它们一起维护的共同分区表。由于此状态本身是日志，因此其他处理器可以订阅它。当处理的目标是更新最终状态并且该状态是处理的自然输出时，这实际上非常有用。

当与来自数据库的日志结合用于数据集成时，日志/表二元性的强大功能变得清晰。可以从数据库中提取变更日志，并且由各种流处理器以不同的形式索引变更日志以加入事件流。

### 记录压缩

![image](https://note.youdao.com/yws/res/22036/AA4576015AA843018CA30905BFFE73E3)

当然，我们不能希望始终保持所有状态变化的完整日志。除非想要使用无限空间，否则必须以某种方式清除日志。

**在Kafka中，清理有两个选项，具体取决于数据是包含键控更新还是事件数据** 。
- 对于事件数据，Kafka仅支持保留数据窗口。通常，这被配置为几天，但窗口可以根据时间或空间来定义。
- 但是，对于键控数据，完整日志的一个不错的属性是您可以重放它以重新创建源系统的状态（可能在另一个系统中重新创建它）。

但是，随着时间的推移，保留完整日志会占用越来越多的空间，重播将花费更长时间。因此，在Kafka，我们支持不同类型的保留。我们不是简单地丢弃旧日志，而是删除过时的记录 - 即主键具有更新更新的记录。通过这样做，我们仍然保证日志包含源系统的完整备份，但现在我们不能再重新创建源系统的所有先前状态，只能重新创建更新的状态。我们将此功能称为**日志压缩**。

## 系统构建

日志在分布式数据库中为数据流服务的角色与在大型组织中为数据集成服务的角色之间有类比。在这两种情况下，它都负责数据流，一致性和恢复。

假设存在外部日志的系统允许各个系统放弃它们自身的许多复杂性并依赖于共享日志。以下是我认为日志可以执行的操作：
- 通过对节点的并发更新进行排序来处理数据一致性（无论是最终的还是立即的）
- 提供节点之间的数据复制
- 为作者提供“提交”语义（即只有当你的写保证不丢失时才确认）
- 从系统提供外部数据订阅源
- 提供恢复丢失数据或引导新副本的失败副本的功能
- 处理节点之间数据的重新平衡。

这实际上是分布式数据系统的重要组成部分。事实上，剩下的大部分内容都与最终面向客户的查询API和索引策略有关。这正是应该因系统而异的部分：例如，**全文搜索查询可能需要查询所有分区，而主键查询可能只需要查询负责该密钥数据的单个节点。**

这是如何工作的。系统分为两个逻辑部分：日志和服务层。日志按顺序捕获状态更改。服务节点存储提供查询所需的任何索引（例如，键值存储可能具有类似btree或sstable的东西，搜索系统将具有反向索引）。写入可以直接转到日志，但它们可能由服务层代理。写入日志会产生逻辑时间戳（比如日志中的索引）。如果系统是分区的，我认为它是，那么日志和服务节点将具有相同数量的分区，尽管它们可能具有非常不同的机器数量。

![image](https://note.youdao.com/yws/res/22052/8146DF57D03A4619A991C807267824F2)

服务节点订阅日志并按照日志存储的顺序尽快将写入应用于其本地索引。

客户端可以通过提供写入的时间戳作为其查询的一部分从任何节点获得读写语义 - 接收此类查询的服务节点将比较期望的时间戳与其自己的索引点，并在必要时将请求延迟到它已经索引至少那个时间，以避免提供陈旧的数据。

服务节点可能需要或可能不需要具有“主控权”或“领导者选举权”的任何概念。对于许多简单的用例，服务节点可以完全没有领导者，因为日志是事实的来源。

**分布式系统必须做的一件棘手的事情是处理恢复故障节点或从一个节点移动到另一个节点的分区**。典型的方法是使日志仅保留固定的数据窗口，并将其与存储在分区中的数据的快照相结合。日志同样可以保留数据的完整副本，并且垃圾收集日志本身。这将大量的复杂性从服务层（特定于系统）移动到日志中，这可以是通用的。

通过使用此日志系统，您可以获得一个完全开发的订阅API，用于将ETL提供给其他系统的数据存储的内容。实际上，许多系统可以在提供不同索引的同时共享相同的日志，如下所示：

![image](https://note.youdao.com/yws/res/22059/E8FD61E1227B48ACBFAB1349B65FA049)



# 总结和参考资料